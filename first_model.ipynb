{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import data_utils\n",
    "import models\n",
    "import importlib\n",
    "import transformer_models\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(models)\n",
    "importlib.reload(transformer_models)\n",
    "from data_utils import *\n",
    "from models import *\n",
    "from transformer_models import * \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "dataObject = xrdData(\"data/\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObject.make_datasets(0.5, composition_embedding=\"composition1D\")\n",
    "# Create DataLoaders for train and validation sets\n",
    "train_loader = DataLoader(dataObject.torch_datasets['train'], batch_size=256, shuffle=True)\n",
    "valid_loader = DataLoader(dataObject.torch_datasets['val'], batch_size=256, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model instance and move it to the selected device\n",
    "output_dim = 230  # Output dimension\n",
    "ConvModel = XRD_C_SymNet(in_channels=1, output_dim=output_dim, composition_model= None).to(device)\n",
    "token_size = 100 #dimension of the tokens \n",
    "TransModel = TransformerModel(ntoken = output_dim, d_model = token_size, nhead = 10, d_hid=100, nlayers=2, dropout = 0.3).to(device)\n",
    "model = TransModel\n",
    "# Define optimizer and loss function\n",
    "weight_decay = 0  # Example value, adjust based on your needs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31369900"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(ConvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993710"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(TransModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.56846564893178"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(ConvModel) / count_parameters(TransModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate experimental data simulator \n",
    "simulator = ExperimentalSimulation(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 4.558626809590299, Training Accuracy: 8.759651169249569%, Validation Loss: 3.990792089038425, Validation Accuracy: 16.095511828432457%\n",
      "Epoch 2, Training Loss: 3.8115406305017605, Training Accuracy: 17.963672721213133%, Validation Loss: 3.645903852250841, Validation Accuracy: 20.05306212690692%\n",
      "Epoch 3, Training Loss: 3.541316052557717, Training Accuracy: 21.424207076598346%, Validation Loss: 3.431872248649597, Validation Accuracy: 22.46296705726288%\n",
      "Epoch 4, Training Loss: 3.3610089765468114, Training Accuracy: 23.646058990168306%, Validation Loss: 3.313508907953898, Validation Accuracy: 24.121158523104135%\n",
      "Epoch 5, Training Loss: 3.21701957810093, Training Accuracy: 26.034549797256012%, Validation Loss: 3.205666330125597, Validation Accuracy: 25.44771169577714%\n",
      "Epoch 6, Training Loss: 3.1267404388374005, Training Accuracy: 27.001055379658947%, Validation Loss: 3.154497093624539, Validation Accuracy: 26.464735794826442%\n",
      "Epoch 7, Training Loss: 3.047223772801144, Training Accuracy: 28.328611898016998%, Validation Loss: 3.092401769426134, Validation Accuracy: 27.702852089321247%\n",
      "Epoch 8, Training Loss: 2.980212235114944, Training Accuracy: 29.63394989723935%, Validation Loss: 3.062524159749349, Validation Accuracy: 28.4324563342914%\n",
      "Epoch 9, Training Loss: 2.918426752090454, Training Accuracy: 30.905960117758152%, Validation Loss: 3.008764558368259, Validation Accuracy: 29.361043555162503%\n",
      "Epoch 10, Training Loss: 2.8650715116044165, Training Accuracy: 31.85580181080931%, Validation Loss: 2.9785603947109647, Validation Accuracy: 30.466504532390008%\n",
      "Epoch 11, Training Loss: 2.807941023732575, Training Accuracy: 32.57234905293562%, Validation Loss: 2.9281300703684487, Validation Accuracy: 31.59407472916206%\n",
      "Epoch 12, Training Loss: 2.7553047630148875, Training Accuracy: 33.28889629506193%, Validation Loss: 2.9208522372775607, Validation Accuracy: 31.88149458324121%\n",
      "Epoch 13, Training Loss: 2.7137593685741157, Training Accuracy: 34.31094817530412%, Validation Loss: 2.8811651203367443, Validation Accuracy: 32.765863365023215%\n",
      "Epoch 14, Training Loss: 2.6765566073672873, Training Accuracy: 35.12747875354108%, Validation Loss: 2.857977681689792, Validation Accuracy: 32.96484634092417%\n",
      "Epoch 15, Training Loss: 2.640574126176431, Training Accuracy: 35.57740376603899%, Validation Loss: 2.841328779856364, Validation Accuracy: 33.650232146805216%\n",
      "Epoch 16, Training Loss: 2.601114310009379, Training Accuracy: 36.66055657390435%, Validation Loss: 2.8053453895780773, Validation Accuracy: 33.561795268627016%\n",
      "Epoch 17, Training Loss: 2.5563840530288053, Training Accuracy: 37.43265011386991%, Validation Loss: 2.782501326666938, Validation Accuracy: 34.003979659518016%\n",
      "Epoch 18, Training Loss: 2.5292621464796468, Training Accuracy: 38.049214019885575%, Validation Loss: 2.78257253434923, Validation Accuracy: 34.77780234357727%\n",
      "Epoch 19, Training Loss: 2.495387309034106, Training Accuracy: 38.626895517413764%, Validation Loss: 2.7546253469255237, Validation Accuracy: 35.35264205173557%\n",
      "Epoch 20, Training Loss: 2.4731973728663483, Training Accuracy: 39.06571127034383%, Validation Loss: 2.744818025165134, Validation Accuracy: 35.08733141720097%\n",
      "Epoch 21, Training Loss: 2.4465253756079877, Training Accuracy: 39.149030717102704%, Validation Loss: 2.7440383036931357, Validation Accuracy: 34.976785319478225%\n",
      "Epoch 22, Training Loss: 2.4245299184826057, Training Accuracy: 39.91001499750042%, Validation Loss: 2.735326369603475, Validation Accuracy: 35.197877514923725%\n",
      "Epoch 23, Training Loss: 2.3872775292732347, Training Accuracy: 40.38215852913403%, Validation Loss: 2.698328521516588, Validation Accuracy: 35.595843466725626%\n",
      "Epoch 24, Training Loss: 2.3623339760471396, Training Accuracy: 40.78764650336055%, Validation Loss: 2.6971487601598105, Validation Accuracy: 35.993809418527526%\n",
      "Epoch 25, Training Loss: 2.3515643502624943, Training Accuracy: 41.309781703049495%, Validation Loss: 2.697268009185791, Validation Accuracy: 36.01591863807207%\n",
      "Epoch 26, Training Loss: 2.3271429975267868, Training Accuracy: 41.14869743931567%, Validation Loss: 2.681825187471178, Validation Accuracy: 36.72341366349768%\n",
      "Epoch 27, Training Loss: 2.2935350176314233, Training Accuracy: 42.19852246847748%, Validation Loss: 2.6840393675698175, Validation Accuracy: 36.48021224850763%\n",
      "Epoch 28, Training Loss: 2.2693869631055374, Training Accuracy: 42.17074931955785%, Validation Loss: 2.678158442179362, Validation Accuracy: 36.59075834623038%\n",
      "Epoch 29, Training Loss: 2.259322142936814, Training Accuracy: 42.80397711492529%, Validation Loss: 2.6760567956500583, Validation Accuracy: 36.63497678531948%\n",
      "Epoch 30, Training Loss: 2.242682589611537, Training Accuracy: 42.64844748097539%, Validation Loss: 2.6761214998033314, Validation Accuracy: 36.54653990714128%\n",
      "Epoch 31, Training Loss: 2.2118207165892696, Training Accuracy: 43.52607898683553%, Validation Loss: 2.6542181306415134, Validation Accuracy: 36.52443068759673%\n",
      "Epoch 32, Training Loss: 2.1921032734320196, Training Accuracy: 44.26484474809754%, Validation Loss: 2.6531461477279663, Validation Accuracy: 36.96661507848773%\n",
      "Epoch 33, Training Loss: 2.169573575678006, Training Accuracy: 44.27595400766539%, Validation Loss: 2.636339134640164, Validation Accuracy: 36.45810302896308%\n",
      "Epoch 34, Training Loss: 2.162226425090306, Training Accuracy: 44.68699661167583%, Validation Loss: 2.637646370463901, Validation Accuracy: 37.47512712801238%\n",
      "Epoch 35, Training Loss: 2.1488211171727785, Training Accuracy: 45.0369382880631%, Validation Loss: 2.6408908896976047, Validation Accuracy: 37.20981649347778%\n",
      "Epoch 36, Training Loss: 2.1273220105909965, Training Accuracy: 44.84808087540966%, Validation Loss: 2.6440389421251087, Validation Accuracy: 37.69621932345788%\n",
      "Epoch 37, Training Loss: 2.1082082802141215, Training Accuracy: 45.76459478975726%, Validation Loss: 2.631985995504591, Validation Accuracy: 37.67411010391333%\n",
      "Epoch 38, Training Loss: 2.082825544854285, Training Accuracy: 45.73126701105371%, Validation Loss: 2.6368530326419406, Validation Accuracy: 38.04996683617068%\n",
      "Epoch 39, Training Loss: 2.0843816374389217, Training Accuracy: 45.881242015219684%, Validation Loss: 2.6500780052608914, Validation Accuracy: 37.56356400619058%\n",
      "Epoch 40, Training Loss: 2.0659748718772137, Training Accuracy: 46.23118369160695%, Validation Loss: 2.656117836634318, Validation Accuracy: 37.762546982091536%\n",
      "Epoch 41, Training Loss: 2.0344235074352213, Training Accuracy: 47.05326889962784%, Validation Loss: 2.6291519138548107, Validation Accuracy: 38.18262215343798%\n",
      "Epoch 42, Training Loss: 2.030704656117399, Training Accuracy: 46.70332722324057%, Validation Loss: 2.6146850056118436, Validation Accuracy: 38.116294494804336%\n",
      "Epoch 43, Training Loss: 2.010811001482144, Training Accuracy: 47.08104204854747%, Validation Loss: 2.624859094619751, Validation Accuracy: 37.69621932345788%\n",
      "Epoch 44, Training Loss: 2.0076010579794223, Training Accuracy: 47.60873187802033%, Validation Loss: 2.6142359177271524, Validation Accuracy: 38.31527747070528%\n",
      "Epoch 45, Training Loss: 1.989664272523262, Training Accuracy: 47.17547075487419%, Validation Loss: 2.626839624510871, Validation Accuracy: 38.71324342250718%\n",
      "Epoch 46, Training Loss: 1.977705391360001, Training Accuracy: 48.15308559684497%, Validation Loss: 2.632329410976834, Validation Accuracy: 38.337386690249836%\n",
      "Epoch 47, Training Loss: 1.9519753943026905, Training Accuracy: 48.57523746042326%, Validation Loss: 2.624483969476488, Validation Accuracy: 38.62480654432898%\n",
      "Epoch 48, Training Loss: 1.9659661541522389, Training Accuracy: 48.08643003943787%, Validation Loss: 2.627800544102987, Validation Accuracy: 38.58058810523988%\n",
      "Epoch 49, Training Loss: 1.9392584176130698, Training Accuracy: 48.44192634560906%, Validation Loss: 2.623568124241299, Validation Accuracy: 39.13331859385364%\n",
      "Epoch 50, Training Loss: 1.9277748171712312, Training Accuracy: 49.4306504471477%, Validation Loss: 2.6270614994896784, Validation Accuracy: 39.04488171567544%\n",
      "Epoch 51, Training Loss: 1.9173210456337728, Training Accuracy: 48.96406154529801%, Validation Loss: 2.642468969027201, Validation Accuracy: 38.53636966615078%\n",
      "Epoch 52, Training Loss: 1.9018970811870737, Training Accuracy: 49.2751208131978%, Validation Loss: 2.6343597968419394, Validation Accuracy: 38.82378952022994%\n",
      "Epoch 53, Training Loss: 1.8920743263943094, Training Accuracy: 49.71393656612787%, Validation Loss: 2.6241406864590116, Validation Accuracy: 39.288083130665484%\n",
      "Epoch 54, Training Loss: 1.8778249126085094, Training Accuracy: 49.74170971504749%, Validation Loss: 2.631470719973246, Validation Accuracy: 38.89011717886358%\n",
      "Epoch 55, Training Loss: 1.8590682073378226, Training Accuracy: 50.10276065100261%, Validation Loss: 2.626126276122199, Validation Accuracy: 39.288083130665484%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[408], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(xrd, composition)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/cdvae/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cdvae/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 200\n",
    "metrics = [\"accuracy\", \"loss\"]\n",
    "\n",
    "log = {\n",
    "    f\"{type}\": {f\"{metric}\" : np.zeros(max_epochs) for metric in metrics} for type in ['train', 'val']     \n",
    "}\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for xrd, composition, targets in train_loader:\n",
    "        if model == TransModel:\n",
    "            xrd = tokenize_xrd(xrd, token_size=token_size)\n",
    "        xrd = F.normalize(xrd, p=2, dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        #xrd = simulator.sim(xrd)\n",
    "        if model == TransModel:\n",
    "            outputs = model(xrd) #add composition support later \n",
    "        else:\n",
    "            outputs = model(xrd, composition)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_valid_loss = 0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for xrd, composition, targets in valid_loader:\n",
    "            if model == TransModel:\n",
    "                xrd = tokenize_xrd(xrd, token_size=token_size)\n",
    "            xrd = F.normalize(xrd, p=2, dim=1)\n",
    "            #xrd = simulator.sim(xrd)\n",
    "            if model == TransModel:\n",
    "                outputs = model(xrd) #add composition support later \n",
    "            else:\n",
    "                outputs = model(xrd, composition)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            total_valid += targets.size(0)\n",
    "            correct_valid += (predicted == targets).sum().item()\n",
    "\n",
    "    valid_accuracy = 100 * correct_valid / total_valid\n",
    "\n",
    "    total_train_loss = total_train_loss / len(train_loader)\n",
    "    validation_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_train_loss}, Training Accuracy: {train_accuracy}%, Validation Loss: {validation_loss}, Validation Accuracy: {valid_accuracy}%\")\n",
    "\n",
    "    log['train']['accuracy'][epoch] = (train_accuracy)\n",
    "    log['train']['loss'][epoch] =(total_train_loss)\n",
    "\n",
    "    log['val']['accuracy'][epoch] =(valid_accuracy)\n",
    "    log['val']['loss'][epoch] =(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m()\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, model_name), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
     ]
    }
   ],
   "source": [
    "model_dir = \"models/\"\n",
    "\n",
    "date = datetime.now()\n",
    "model_name = f\"first_model_{date.month}_{date.day}\"\n",
    "\n",
    "os.makedirs(os.path.join(model_dir, model_name), exist_ok=True)\n",
    "\n",
    "torch.save(model, os.path.join(model_dir, model_name, 'model.pth'))\n",
    "\n",
    "for data_type, metrics_dict in log.items():\n",
    "    for metric, array in metrics_dict.items():\n",
    "        filename = f\"{data_type}_{metric}.npy\"  # Construct filename, e.g., \"train_accuracy.npy\"\n",
    "        filename = os.path.join(model_dir, model_name, filename)\n",
    "        np.save(filename, array)  # Save the array to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
