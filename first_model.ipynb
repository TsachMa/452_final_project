{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import data_utils\n",
    "import models\n",
    "import importlib\n",
    "import transformer_models\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(models)\n",
    "importlib.reload(transformer_models)\n",
    "from data_utils import *\n",
    "from models import *\n",
    "from transformer_models import * \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "dataObject = xrdData(\"data/\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObject.make_datasets(1, composition_embedding=\"composition1D\")\n",
    "# Create DataLoaders for train and validation sets\n",
    "train_loader = DataLoader(dataObject.torch_datasets['train'], batch_size=256, shuffle=True)\n",
    "valid_loader = DataLoader(dataObject.torch_datasets['val'], batch_size=256, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12160\n"
     ]
    }
   ],
   "source": [
    "# Create the model instance and move it to the selected device\n",
    "output_dim = 230  # Output dimension\n",
    "ConvModel = XRD_C_SymNet(in_channels=1, output_dim=output_dim, composition_model= None).to(device)\n",
    "token_size = 50 #dimension of the tokens \n",
    "TransModel = TransformerModel(ntoken = output_dim, d_model = token_size, nhead = 10, d_hid=50, nlayers=1, dropout = 0.5).to(device)\n",
    "model = ConvModel\n",
    "# Define optimizer and loss function\n",
    "weight_decay = 0  # Example value, adjust based on your needs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31369900"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(ConvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148027400"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(TransModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21191955002925134"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(ConvModel) / count_parameters(TransModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate experimental data simulator \n",
    "simulator = ExperimentalSimulation(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 3.166233497308501, Training Accuracy: 28.303616063989335%, Validation Loss: 2.4453689787122936, Validation Accuracy: 40.99049303559585%\n",
      "Epoch 2, Training Loss: 2.3027346184913147, Training Accuracy: 44.6675554074321%, Validation Loss: 2.0642301771375866, Validation Accuracy: 49.17090426707937%\n",
      "Epoch 3, Training Loss: 1.940155248269967, Training Accuracy: 52.069099594512025%, Validation Loss: 1.7931274440553453, Validation Accuracy: 54.963519787751494%\n",
      "Epoch 4, Training Loss: 1.6914627053213458, Training Accuracy: 57.20713214464256%, Validation Loss: 1.6237857275538974, Validation Accuracy: 58.235684280344906%\n",
      "Epoch 5, Training Loss: 1.5088031444143741, Training Accuracy: 60.96761650835972%, Validation Loss: 1.570229967435201, Validation Accuracy: 60.09285872208711%\n",
      "Epoch 6, Training Loss: 1.3534991047906537, Training Accuracy: 64.26428928511915%, Validation Loss: 1.417560186651018, Validation Accuracy: 63.54189697103692%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m total_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 200\n",
    "metrics = [\"accuracy\", \"loss\"]\n",
    "\n",
    "log = {\n",
    "    f\"{type}\": {f\"{metric}\" : np.zeros(max_epochs) for metric in metrics} for type in ['train', 'val']     \n",
    "}\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for xrd, composition, targets in train_loader: \n",
    "        xrd = F.normalize(xrd, p=2, dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        #xrd = simulator.sim(xrd)\n",
    "        if model == TransModel:\n",
    "            outputs = model(xrd) #add composition support later \n",
    "        else:\n",
    "            outputs = model(xrd, composition)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_valid_loss = 0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for xrd, composition, targets in valid_loader:\n",
    "            xrd = F.normalize(xrd, p=2, dim=1)\n",
    "            #xrd = simulator.sim(xrd)\n",
    "            if model == TransModel:\n",
    "                outputs = model(xrd) #add composition support later \n",
    "            else:\n",
    "                outputs = model(xrd, composition)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            total_valid += targets.size(0)\n",
    "            correct_valid += (predicted == targets).sum().item()\n",
    "\n",
    "    valid_accuracy = 100 * correct_valid / total_valid\n",
    "\n",
    "    total_train_loss = total_train_loss / len(train_loader)\n",
    "    validation_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_train_loss}, Training Accuracy: {train_accuracy}%, Validation Loss: {validation_loss}, Validation Accuracy: {valid_accuracy}%\")\n",
    "\n",
    "    log['train']['accuracy'][epoch] = (train_accuracy)\n",
    "    log['train']['loss'][epoch] =(total_train_loss)\n",
    "\n",
    "    log['val']['accuracy'][epoch] =(valid_accuracy)\n",
    "    log['val']['loss'][epoch] =(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m()\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, model_name), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
     ]
    }
   ],
   "source": [
    "model_dir = \"models/\"\n",
    "\n",
    "date = datetime.now()\n",
    "model_name = f\"first_model_{date.month}_{date.day}\"\n",
    "\n",
    "os.makedirs(os.path.join(model_dir, model_name), exist_ok=True)\n",
    "\n",
    "torch.save(model, os.path.join(model_dir, model_name, 'model.pth'))\n",
    "\n",
    "for data_type, metrics_dict in log.items():\n",
    "    for metric, array in metrics_dict.items():\n",
    "        filename = f\"{data_type}_{metric}.npy\"  # Construct filename, e.g., \"train_accuracy.npy\"\n",
    "        filename = os.path.join(model_dir, model_name, filename)\n",
    "        np.save(filename, array)  # Save the array to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
