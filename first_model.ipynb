{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> 6f68613 (minor changes)
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import data_utils\n",
    "import models\n",
    "import importlib\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(models)\n",
    "from data_utils import *\n",
    "from models import *\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 4,
>>>>>>> 6f68613 (minor changes)
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "dataObject = xrdData(\"data/\", device)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObject.make_datasets(0.5, composition_embedding=\"composition1D\")\n",
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObject.make_datasets(1, composition_embedding=\"composition1D\")\n",
>>>>>>> 6f68613 (minor changes)
    "# Create DataLoaders for train and validation sets\n",
    "train_loader = DataLoader(dataObject.torch_datasets['train'], batch_size=256, shuffle=True)\n",
    "valid_loader = DataLoader(dataObject.torch_datasets['val'], batch_size=256, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
=======
   "execution_count": 6,
>>>>>>> 6f68613 (minor changes)
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model instance and move it to the selected device\n",
    "output_dim = 230  # Output dimension\n",
    "model = XRD_C_SymNet(in_channels=1, output_dim=output_dim, composition_model= None).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "weight_decay = 0  # Example value, adjust based on your needs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 4.155010659929732, Training Accuracy: 13.892129089596178%, Validation Loss: 3.967201762729221, Validation Accuracy: 15.896528852531505%\n",
      "Epoch 2, Training Loss: 3.8576592626705977, Training Accuracy: 16.269510637116035%, Validation Loss: 3.738280256589254, Validation Accuracy: 18.107450806986513%\n",
      "Epoch 3, Training Loss: 3.723875361429134, Training Accuracy: 17.652613453313336%, Validation Loss: 3.887420137723287, Validation Accuracy: 16.648242317046208%\n",
      "Epoch 4, Training Loss: 3.6607676861991343, Training Accuracy: 18.513581069821697%, Validation Loss: 3.688563664754232, Validation Accuracy: 18.682290515144814%\n",
      "Epoch 5, Training Loss: 3.589973036672028, Training Accuracy: 19.352330167194356%, Validation Loss: 3.751904739273919, Validation Accuracy: 16.007074950254257%\n",
      "Epoch 6, Training Loss: 3.558655201549261, Training Accuracy: 19.885574626451145%, Validation Loss: 3.5392675267325506, Validation Accuracy: 19.54455007738227%\n",
      "Epoch 7, Training Loss: 3.506977020854681, Training Accuracy: 20.518802421818584%, Validation Loss: 3.7597476508882313, Validation Accuracy: 18.461198319699314%\n",
      "Epoch 8, Training Loss: 3.475799557188867, Training Accuracy: 21.24090429372882%, Validation Loss: 3.432252460055881, Validation Accuracy: 21.866018129560025%\n",
      "Epoch 9, Training Loss: 3.4380365022471255, Training Accuracy: 21.524190412708993%, Validation Loss: 3.6602705452177258, Validation Accuracy: 18.439089100154764%\n",
      "Epoch 10, Training Loss: 3.403580729390534, Training Accuracy: 22.046325612397933%, Validation Loss: 3.5356524652904935, Validation Accuracy: 20.804775591421624%\n",
      "Epoch 11, Training Loss: 3.362147331237793, Training Accuracy: 22.585124701438648%, Validation Loss: 3.400547001096937, Validation Accuracy: 21.998673446827326%\n",
      "Epoch 12, Training Loss: 3.347826830098327, Training Accuracy: 22.968394156529467%, Validation Loss: 3.3638402620951333, Validation Accuracy: 23.01569754587663%\n",
      "Epoch 13, Training Loss: 3.313995122909546, Training Accuracy: 23.373882130755984%, Validation Loss: 3.275982936223348, Validation Accuracy: 24.651779792173336%\n",
      "Epoch 14, Training Loss: 3.2853170952326813, Training Accuracy: 23.601621951896906%, Validation Loss: 3.3032347626156278, Validation Accuracy: 23.54631881494583%\n",
      "Epoch 15, Training Loss: 3.2590018863409336, Training Accuracy: 24.40148864078209%, Validation Loss: 3.3466807206471763, Validation Accuracy: 23.43577271722308%\n",
      "Epoch 16, Training Loss: 3.2431254991343326, Training Accuracy: 24.97917013831028%, Validation Loss: 3.2770131296581693, Validation Accuracy: 24.474906035816936%\n",
      "Epoch 17, Training Loss: 3.217531472864285, Training Accuracy: 25.07915347442093%, Validation Loss: 3.2322958840264215, Validation Accuracy: 25.86778686712359%\n",
      "Epoch 18, Training Loss: 3.194919461935339, Training Accuracy: 25.762372937843693%, Validation Loss: 3.23031128777398, Validation Accuracy: 25.51403935441079%\n",
      "Epoch 19, Training Loss: 3.174536275192046, Training Accuracy: 26.02899516747209%, Validation Loss: 3.202095866203308, Validation Accuracy: 26.00044218439089%\n",
      "Epoch 20, Training Loss: 3.15179936986574, Training Accuracy: 26.340054435371883%, Validation Loss: 3.231447842386034, Validation Accuracy: 26.354189697103692%\n",
      "Epoch 21, Training Loss: 3.140192112452547, Training Accuracy: 26.6788868521913%, Validation Loss: 3.1916976239946155, Validation Accuracy: 27.128012381162947%\n",
      "Epoch 22, Training Loss: 3.127462863922119, Training Accuracy: 27.095484085985667%, Validation Loss: 3.1913486851586237, Validation Accuracy: 26.730046429361042%\n",
      "Epoch 23, Training Loss: 3.08395401189025, Training Accuracy: 27.723157251569184%, Validation Loss: 3.1751037571165295, Validation Accuracy: 27.525978332964847%\n",
      "Epoch 24, Training Loss: 3.075368820781439, Training Accuracy: 27.92312392379048%, Validation Loss: 3.151918795373705, Validation Accuracy: 27.194340039796597%\n",
      "Epoch 25, Training Loss: 3.047507648736658, Training Accuracy: 28.256401710825973%, Validation Loss: 3.126708600256178, Validation Accuracy: 28.6535485297369%\n",
      "Epoch 26, Training Loss: 3.0513918466970953, Training Accuracy: 28.1730822640671%, Validation Loss: 3.1549576918284097, Validation Accuracy: 27.901835065222198%\n",
      "Epoch 27, Training Loss: 3.001697768627758, Training Accuracy: 28.94517580403266%, Validation Loss: 3.1278124120500355, Validation Accuracy: 27.636524430687597%\n",
      "Epoch 28, Training Loss: 2.9986465883926607, Training Accuracy: 28.917402655113037%, Validation Loss: 3.1703139543533325, Validation Accuracy: 27.724961308865797%\n",
      "Epoch 29, Training Loss: 2.980281030628043, Training Accuracy: 29.367327667610954%, Validation Loss: 3.116207308239407, Validation Accuracy: 28.233473358390448%\n",
      "Epoch 30, Training Loss: 2.971542324818356, Training Accuracy: 29.472865633505528%, Validation Loss: 3.1234605577256946, Validation Accuracy: 27.813398187043997%\n",
      "Epoch 31, Training Loss: 2.9450593934932225, Training Accuracy: 30.29495084152641%, Validation Loss: 3.1313636302948, Validation Accuracy: 26.906920185717443%\n",
      "Epoch 32, Training Loss: 2.934360537730472, Training Accuracy: 29.945009165139144%, Validation Loss: 3.0612810055414834, Validation Accuracy: 29.692681848330754%\n",
      "Epoch 33, Training Loss: 2.9222196122290383, Training Accuracy: 30.150530467144364%, Validation Loss: 3.069392893049452, Validation Accuracy: 29.272606676984303%\n",
      "Epoch 34, Training Loss: 2.9041163182594407, Training Accuracy: 30.60045547964228%, Validation Loss: 3.0413780079947577, Validation Accuracy: 29.714791067875304%\n",
      "Epoch 35, Training Loss: 2.897303735706168, Training Accuracy: 30.589346220074432%, Validation Loss: 3.0811428361468844, Validation Accuracy: 29.206279018350653%\n",
      "Epoch 36, Training Loss: 2.8852572944802297, Training Accuracy: 31.411431428095316%, Validation Loss: 3.114268938700358, Validation Accuracy: 29.515808091974353%\n",
      "Epoch 37, Training Loss: 2.875007125693308, Training Accuracy: 31.067044381491975%, Validation Loss: 3.2358534733454385, Validation Accuracy: 27.150121600707497%\n",
      "Epoch 38, Training Loss: 2.8585762473898875, Training Accuracy: 31.489196245070268%, Validation Loss: 3.1122053596708508, Validation Accuracy: 28.808313066548752%\n",
      "Epoch 39, Training Loss: 2.821033434129097, Training Accuracy: 31.94467588735211%, Validation Loss: 3.0787682135899863, Validation Accuracy: 29.714791067875304%\n",
      "Epoch 40, Training Loss: 2.8220307021073894, Training Accuracy: 32.450147197689276%, Validation Loss: 3.0418445004357233, Validation Accuracy: 30.488613751934558%\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 6f68613 (minor changes)
   "source": [
    "max_epochs = 100\n",
    "metrics = [\"accuracy\", \"loss\"]\n",
    "\n",
    "log = {\n",
    "    f\"{type}\": {f\"{metric}\" : np.zeros(max_epochs) for metric in metrics} for type in ['train', 'val']     \n",
    "}\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for xrd, composition, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        xrd = simulator.sim(xrd)\n",
    "        outputs = model(xrd, composition)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_valid_loss = 0\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for xrd, composition, targets in valid_loader:\n",
    "            xrd = simulator.sim(xrd)\n",
    "            outputs = model(xrd, composition)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            total_valid += targets.size(0)\n",
    "            correct_valid += (predicted == targets).sum().item()\n",
    "\n",
    "    valid_accuracy = 100 * correct_valid / total_valid\n",
    "\n",
    "    total_train_loss = total_train_loss / len(train_loader)\n",
    "    validation_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_train_loss}, Training Accuracy: {train_accuracy}%, Validation Loss: {validation_loss}, Validation Accuracy: {valid_accuracy}%\")\n",
    "\n",
    "    log['train']['accuracy'][epoch] = (train_accuracy)\n",
    "    log['train']['loss'][epoch] =(total_train_loss)\n",
    "\n",
    "    log['val']['accuracy'][epoch] =(valid_accuracy)\n",
    "    log['val']['loss'][epoch] =(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"models/\"\n",
    "\n",
    "date = datetime.now()\n",
    "model_name = f\"first_model_{date.month}_{date.day}\"\n",
    "\n",
    "os.makedirs(os.path.join(model_dir, model_name), exist_ok=True)\n",
    "\n",
    "torch.save(model, os.path.join(model_dir, model_name, 'model.pth'))\n",
    "\n",
    "for data_type, metrics_dict in log.items():\n",
    "    for metric, array in metrics_dict.items():\n",
    "        filename = f\"{data_type}_{metric}.npy\"  # Construct filename, e.g., \"train_accuracy.npy\"\n",
    "        filename = os.path.join(model_dir, model_name, filename)\n",
    "        np.save(filename, array)  # Save the array to a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc552v2",
   "language": "python",
   "name": "cpsc552v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
