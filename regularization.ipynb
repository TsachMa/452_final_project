{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51d955-d2fb-4d96-b542-efb9ef376a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import data_utils\n",
    "import models\n",
    "import importlib\n",
    "import transformer_models\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(models)\n",
    "importlib.reload(transformer_models)\n",
    "from data_utils import *\n",
    "from models import *\n",
    "from transformer_models import * \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datetime\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad7841-b937-412f-af80-e4d596ce9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "dataObject = xrdData(\"data/\", device)\n",
    "\n",
    "dataObject.make_datasets(1, composition_embedding=\"compositionseq\")\n",
    "# Create DataLoaders for train and validation sets\n",
    "train_loader = DataLoader(dataObject.torch_datasets['train'], batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataObject.torch_datasets['val'], batch_size=32, shuffle=False)\n",
    "simulator = ExperimentalSimulation(device, crop_start=500, crop_stop = 500, noise_range = 0.1, drop_width = 100, drop_freq = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1db37-e391-4e38-9ffe-9d6b487a8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedLoss(nn.Module):\n",
    "    def __init__(self, model, criterion=nn.CrossEntropyLoss(), l1=0, l2=0, full=True):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.full = full\n",
    "        \n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "\n",
    "    def __call__(self, pred, target):\n",
    "        # print(self.criterion)\n",
    "        loss = self.criterion(pred, target)\n",
    "        # print(loss)\n",
    "        l1_reg = torch.tensor(0., requires_grad=True)\n",
    "        l2_reg = torch.tensor(0., requires_grad=True)\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'weight' in name and (self.full or 'elem_former' in name):\n",
    "                # print(torch.sum(torch.abs(param), dim=None))\n",
    "                # print(l1_reg)\n",
    "                l1_reg = l1_reg + torch.sum(torch.abs(param), dim=None)\n",
    "                # l2_reg = l2_reg + torch.sqrt(torch.sum(torch.pow(param, 2), dim=None))\n",
    "        # print(l1_reg)\n",
    "        # print(loss, self.l2 * l2_reg)\n",
    "        return loss + self.l1 * l1_reg + self.l2 * l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c566f-33e8-498e-9477-142b02a9118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "max_epochs = 125\n",
    "metrics = [\"accuracy\", \"loss\"]\n",
    "\n",
    "log = {\n",
    "    f\"{type}\": {f\"{metric}\" : np.zeros(max_epochs) for metric in metrics} for type in ['train', 'val']     \n",
    "}\n",
    "\n",
    "model_df = pd.DataFrame(columns=['model', 'epoch', 'type', 'loss', 'accuracy'])\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb689f-4dab-4e74-9903-079287f9427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_pickle('regularized_model_data.pkl')\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389eaf73-3555-4c96-921a-e7187020a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(fname='train'):\n",
    "    final_epoch = 0\n",
    "    try:\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()  # Set the model to training mode\n",
    "            total_train_loss = 0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            \n",
    "            for xrd, composition, targets in tqdm(train_loader):\n",
    "                xrd = simulator.sim(xrd)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(xrd, composition)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "        \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total_train += targets.size(0)\n",
    "                correct_train += (predicted == targets).sum().item()\n",
    "        \n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            total_valid_loss = 0\n",
    "            correct_valid = 0\n",
    "            total_valid = 0\n",
    "        \n",
    "            with torch.no_grad():  # No gradients needed for validation\n",
    "                for xrd, composition, targets in tqdm(valid_loader):\n",
    "                    xrd = simulator.sim(xrd)\n",
    "                    outputs = model(xrd, composition)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    total_valid_loss += loss.item()\n",
    "        \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    \n",
    "                    total_valid += targets.size(0)\n",
    "                    correct_valid += (predicted == targets).sum().item()\n",
    "        \n",
    "            valid_accuracy = 100 * correct_valid / total_valid\n",
    "        \n",
    "            train_loss = total_train_loss / len(train_loader)\n",
    "            valid_loss = total_valid_loss / len(valid_loader)\n",
    "        \n",
    "            print(f\"Epoch {epoch+1}, Training Loss: {train_loss}, Training Accuracy: {train_accuracy}%, Validation Loss: {valid_loss}, Validation Accuracy: {valid_accuracy}%\")\n",
    "        \n",
    "            # log['train']['accuracy'][epoch] = (train_accuracy)\n",
    "            # log['train']['loss'][epoch] =(total_train_loss)\n",
    "        \n",
    "            # log['val']['accuracy'][epoch] =(valid_accuracy)\n",
    "            # log['val']['loss'][epoch] =(validation_loss)\n",
    "            \n",
    "            model_df.loc[len(model_df)] = [fname, epoch, 'train', train_loss, train_accuracy]\n",
    "            model_df.loc[len(model_df)] = [fname, epoch, 'valid', valid_loss, valid_accuracy]\n",
    "        \n",
    "            final_epoch = epoch\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(f'Interrupting training at epoch {final_epoch}')\n",
    "        \n",
    "\n",
    "    # plt.plot(log['train']['accuracy'][:final_epoch])\n",
    "    # plt.plot(log['val']['accuracy'][:final_epoch])\n",
    "    # plt.savefig(f'{fname}.png')\n",
    "\n",
    "    return final_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec30b2-76b7-4fde-b4a8-cd97964fa633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model instance and move it to the selected device\n",
    "output_dim = 230  # Output dimension\n",
    "ConvModel = XRD_C_SymNet(in_channels=1, output_dim=output_dim, composition_model= None).to(device)\n",
    "token_size = 10 #dimension of the tokens \n",
    "TransModel = FullModel(ntoken = output_dim, d_model = token_size, nhead = 10, d_hid=50, nlayers=1, dropout = 0.5).to(device)\n",
    "model = TransModel\n",
    "\n",
    "# Define optimizer and loss function\n",
    "weight_decay = 0  # Example value, adjust based on your needs\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e5bfd-69d1-4dbe-9309-2845b339c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20, 10)\n",
    "sns.lineplot(data=model_df, x='epoch', y='accuracy', hue='model', style='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acabe75-1b31-43b2-8f06-8a160477d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=model_df, x='epoch', y='loss', hue='model', style='type')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Specific Environment",
   "language": "python",
   "name": "452proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
