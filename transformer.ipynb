{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_models\n",
    "import importlib\n",
    "importlib.reload(transformer_models)\n",
    "from transformer_models import TransformerModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntoken = 230\n",
    "d_model = 500\n",
    "difFormer = TransformerModel(ntoken, d_model, nhead = 4, d_hid=5, nlayers=3, dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n token is the number of classes of words, it's out ouput dimension\n",
    "#d model is the number of features that the positional embedding expects to get per token\n",
    "#nheads is the number of heads \n",
    "#d-hid is the dimension of the hidden layers\n",
    "#n-layers is the number of layers \n",
    "#dropout is dropout \n",
    "source = torch.rand((8, 1, 8500)).to(device) # [seq_len, batch_size, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=500, out_features=500, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=500, out_features=5, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=5, out_features=500, bias=True)\n",
       "        (norm1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=500, out_features=500, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=500, out_features=5, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=5, out_features=500, bias=True)\n",
       "        (norm1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=500, out_features=500, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=500, out_features=5, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=5, out_features=500, bias=True)\n",
       "        (norm1): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((500,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ConvEmb): XRD_ConvEmb(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (conv_layers): Sequential(\n",
       "      (0): Conv1d(1, 80, kernel_size=(100,), stride=(5,))\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Conv1d(80, 80, kernel_size=(50,), stride=(5,))\n",
       "      (5): ReLU()\n",
       "      (6): Dropout(p=0.3, inplace=False)\n",
       "      (7): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): Conv1d(80, 80, kernel_size=(25,), stride=(2,))\n",
       "      (9): ReLU()\n",
       "      (10): Dropout(p=0.3, inplace=False)\n",
       "      (11): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (MLP): Sequential(\n",
       "      (0): Linear(in_features=12160, out_features=30000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=30000, out_features=2300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2300, out_features=1150, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=1150, out_features=230, bias=True)\n",
       "  )\n",
       "  (pooler): AvgPool1d(kernel_size=(17,), stride=(17,), padding=(0,))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difFormer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 30000])\n"
     ]
    }
   ],
   "source": [
    "transformer_output = difFormer(source) # output Tensor of shape ``[seq_len, batch_size, ntoken]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 230])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
